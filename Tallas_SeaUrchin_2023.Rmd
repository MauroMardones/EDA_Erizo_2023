---
title: "Pesquería Erizo X y XI Regiones "
subtitle: "Análisis Exploratorio Datos Tallas Seguimiento Bentónico 1996-2023"
author: "Mauricio Mardones. Inv. Depto Ev. Recursos. IFOP"
date:  "`r format(Sys.time(), '%d %B, %Y')`"
toc: true
toc-title: "Tabla de Contenidos"
format:
  html:
    theme: cosmo
    fontsize: 0.9em
    linestretch: 1.7
    html-math-method: katex
    self-contained: true
    embed-resources: true
    code-tools: true
#bibliography: biblio.bib
#csl: apa.csl
#link-citations: yes
#linkcolor: blue
---


### Set de trabajo y librerías utilizadas

```{r setup}
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE,
                      fig.path="Figuras/")
```


```{r Xquarz_bug}
options(bitmapType = "cairo") 
#XQuartz is a mess, put this in your onload to default to cairo instead (https://github.com/tidyverse/ggplot2/issues/2655)
# Lo mapas se hacen mas rapido
# solo para IOs
```


```{r error=F}
library(GGally)
library(knitr)
library(tidyverse)
library(patchwork)
library(marmap)
library(mapproj)
library(maps)
library(raster)
library(knitr)
library(ggrepel)
library(sf)
library(ggthemes) # nuevos fondos
library(readxl)
library(performance)
library(ggridges)
library(see)
```



\pagebreak

### Analisis exploratorio y preparación de estructuras de tallas para la evaluación de stockde erizo en las 3 macrozonas.

En este documento se presentan las rutas de análisis exploratorio  de estructuras de tallas para cada una de las zonas de evaluación de stock de erizo, a saber; Macrozona X Norte, X Sur y XI, que lleva a cabo el Departamento de Evaluación de Recursos.


\pagebreak

## Exploración de datos totales

Los datos se actualizan año a año y se van estructurando las estructuras de tallas para cada zona de evaluación

```{r data}
ta9622 <- read.table("Tallas_96_22.csv",sep=",", header = T)
names(ta9622)
dim(ta9622)
# leo la base de tallas
ta23 <- read_excel("BD_Erizo_2023.xlsx", 
    sheet = "Tallas")
```


Selecciono las columnas en función de `ta96_22`
```{r}
ta23b <- ta23 %>% 
  dplyr::select(c("REGION",
                  "PUERTO" ,
                  "ANO_ARR",
                  "MES_ARR" ,
                  "DIA_ARR" ,
                  "FUNCION" ,
                  "PROCED"  ,
                  "CAPTURA"  ,
                  "DESTINO" ,
                  "PESO_M"  ,
                  "LONGITUD",
                   "FRECUENCIA")) 
ta9622b <- ta9622 %>% 
  dplyr::select(-1)
ta9623 <- rbind(ta9622b, ta23b)
write_csv(ta9623, "Tallas_96_23.csv")
```


Una vez realizado el cbind, procedo a hacer los cruces con los poligonos

```{r}
pro <- read.csv2("M_Procedencias.csv", header =T, sep=";")
proifop <- read.csv2("M_Procedencias_Poligonos.csv", header =T, sep=",")
names(pro)
names(proifop)
policru<- subset(proifop, select=c(4,5,21, 19,  20))
names(policru)
colnames(policru)<- c("PROCED", "POLIGONO", "POLIGONO_IFOP", "LAT" , "LON")
names(policru)

tageo9623 <- merge(policru, ta9623, by="PROCED")
```

Identifico los registros por año para comprobar lo del 2022

```{r}
table(tageo9623$ANO_ARR)
```




```{r}
# Comandos para crear nueva columna de zona  en funcion de los poligonos

tageo9623$ZONA[tageo9623$POLIGONO %in% c(1,2)] <-1
tageo9623$ZONA[tageo9623$POLIGONO %in% c(4,5,6,13)] <-2
tageo9623$ZONA[tageo9623$POLIGONO %in% c(7,8,9,10,11,12)] <-3

tageo9623$ZONA<- as.factor(tageo9623$ZONA)
class(tageo9623$ZONA)
```


Lo primero es ver diferencias entre destinos

El data frame que corresponde usar es el de *"talla2020"*
```{r fig.cap="Diferencia entre tallas y destino (Fresco e Industria)"}
p <- ggplot(tageo9623, 
            aes(x=LONGITUD, 
                group=DESTINO, 
                fill= DESTINO)) +
    geom_density(alpha=0.4, 
                 show.legend = FALSE)+
    facet_wrap(.~ANO_ARR, 
               scales = "free_y", 
               ncol=5) +
    geom_vline(xintercept = 65, 
               color = "red")+
    xlim(40,150)+
    xlab("Longitud (mm.)")+
    theme_few()
p 
```

```{r, fig.align="center"}
meant <-tageo9623 %>% 
  dplyr::group_by(ANO_ARR, 
           ZONA) %>%
  dplyr::summarise(avg=mean(LONGITUD))
glimpse(meant)
```

```{r, fig.align="center", message=F}
pmea <- ggplot(meant %>% 
                 drop_na(), 
               aes(ANO_ARR,avg))+
    geom_point(shape=21,  aes(fill=ZONA)) +
    stat_smooth(method= "gam", colour='#253494')+
    theme_few()+ 
    facet_wrap(.~ZONA)+
    scale_x_continuous(breaks = seq(from = 1996, 
                                    to = 2022, 
                                    by = 2))+
    #scale_y_discrete(breaks = seq(from = 1, to = 13, by = 1))+
    theme(axis.text.x = element_text(angle = 90, 
                                     hjust = 2),
          legend.position = "bottom")+
    guides(fill = guide_legend(reverse=F))+
    scale_fill_viridis_d(option="E",
                         name="SubArea",
                         labels = c("X NORTE", "X SUR", "XI"))+
    ylim(60,100)+
    ylab("") +
    xlab("") +
    ggtitle("")
pmea
```

## Expansión de tallas para todos los registros. 

Ahora se genera la expansion de tallas a la frecuecnia para obtener los vectores por año y por zona

```{r}
tageo9623b <- tageo9623 %>% 
  drop_na() %>% 
  type.convert(as.is = TRUE) %>% 
  uncount(FRECUENCIA)
```


Identifico las procedencias de la base

```{r}
#table(dftalla4$PROC)
unique(tageo9623b$PROC)
```



\pagebreak

# Comparaciòn de serie historica de las series

comparo los 2 ultimos años por mes y poligono

```{r}
jz <- ggplot(tageo9623b %>% 
                drop_na() %>% 
               filter(ANO_ARR %in% c(2022,2023)),
             aes(x=LONGITUD,
                 y = as.factor(MES_ARR)))+
  #geom_joy(alpha=0.9) +
  geom_density_ridges(stat = "binline", bins = 40, 
                      scale = 1, draw_baseline = FALSE)+
  facet_wrap(.~ANO_ARR, ncol=2) +   
  geom_vline(xintercept = 65, color = "red")+
  #scale_x_continuous(breaks = seq(from = 1, to = 10, by = 1))+
  #scale_y_discrete(breaks = seq(from = 2000, to = 2022, by = 1))+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  xlim(20,140)+
  xlab("Longitud (cm.)")+
  ylab("")
jz


p <- ggplot(tageo9623b %>% 
                drop_na() %>% 
               filter(ANO_ARR %in% c(2022,2023)), 
            aes(x=LONGITUD, 
                group=ANO_ARR, 
                colour= ANO_ARR)) +
    geom_density(alpha=0.4,
                 show.legend = F)+
    facet_wrap(.~ZONA, 
               scales = "free_y") +
    geom_vline(xintercept = 65, 
               color = "red")+
  scale_colour_viridis_c(option = "H")+
    xlim(40,150)+
    xlab("Longitud (mm.)")+
    theme_few()
p 
```




Ahora voy a sacar tallas medias por año y por POLIGONO para graficar. 

```{r, fig.align="center"}
meanproc <-tageo9623b %>% 
  group_by(POLIGONO, ANO_ARR) %>%
  summarise(avg=mean(LONGITUD, rm.na=TRUE))
head(meanproc)
dim(meanproc)
glimpse(meanproc)
```


```{r, fig.align="center"}
mn<-ggplot(meanproc, aes(ANO_ARR, POLIGONO, 
                         size=avg,
                         fill= avg))+
    geom_point(alpha=0.5, 
               shape=21, 
               show.legend = T) +
    scale_size(range = c(-4,10)) +
    scale_x_continuous(breaks = seq(from = 1996, 
                                    to = 2023, 
                                    by = 1))+
    scale_y_continuous(breaks = seq(from = 1, 
                                    to = 13, 
                                    by = 1))+
    guides(fill = guide_legend(reverse=F))+
    theme_bw()+ 
    ylab("") +
    xlab("") +
    coord_flip()
mn
```
compara los grupos de tallas por año estadisticamente


```{r}
ta23 <- tageo9623b %>% 
  filter(ANO_ARR==2023) %>% 
  dplyr::select(LONGITUD)
ta22 <- tageo9623b %>% 
  filter(ANO_ARR==2022) %>% 
  dplyr::select(LONGITUD)

# mide las diferencias entre años
t_student <- t.test(ta22, ta23)
t_welch <- t.test(ta22, ta23, 
                            var.equal = FALSE)

```


\pagebreak

## Prepara los vectores para sumar a los .dat del año 2023

selecciono por poligonos.

```{r eval=FALSE}
### Zona X Norte
tallaxnorte <- tageo9623b %>% 
  filter(POLIGONO==1 | POLIGONO ==2)  %>% 
  filter(ANO_ARR==2023)
tallaxnorte$cat_long <- as.numeric(as.character(cut(x = tallaxnorte$LONGITUD, 
                                                    breaks = seq(40,138,2), 
                                                  labels = seq(40,136,2), 
                                                  right = FALSE)))
ttn <- table(tallaxnorte$ANO_ARR, tallaxnorte$cat_long)

tail(ttn, 10)
### Zona X Sur
tallaxsur <- tageo9623 %>% 
  filter(POLIGONO == 4 | POLIGONO == 5 |
                     POLIGONO == 6 | POLIGONO == 13)  %>% 
  filter(ANO_ARR==2023)
tallaxsur$cat_long <- as.numeric(as.character(cut(x = tallaxsur$LONGITUD, 
                                                  breaks = seq(40,138,2), 
                                                  labels = seq(40,136,2), 
                                                  right = FALSE)))
tts <- table(tallaxsur$ANO_ARR, tallaxsur$cat_long)
tail(tts, 10)
### Zona XI
tallaxi <- tageo9623b %>% 
  filter(POLIGONO == 7 |
                   POLIGONO == 8 |
                   POLIGONO == 9|
                   POLIGONO == 10 |
                   POLIGONO == 11|
                   POLIGONO == 12)  %>% 
  filter(ANO_ARR==2023)
tallaxi$cat_long <- as.numeric(as.character(cut(x = tallaxi$LONGITUD,
                                                breaks = seq(40,138,2), 
                                                  labels = seq(40,136,2), 
                                                right = FALSE)))
ttxi <- table(tallaxi$ANO_ARR, tallaxi$cat_long)
```

Ahora escribo los datos en un `csv`

```{r}
tatodos <-  list(ttn, tts, ttxi)
# Especifica los nombres de los archivos CSV
ttnames <- c("ttn.csv", "tts.csv", "ttxi.csv")
# Guarda cada dataframe en un archivo CSV
for (i in seq_along(tatodos)) {
  write.csv(tatodos[[i]], 
            file = ttnames[i], 
            row.names = FALSE)
}
```

## Mapa de tallas medias


### Tallas engrilladas

ahora prceso los datos de tallas dentro de la grilla `Grid2`. debo sacar los datos `NA`



```{r eval=F}
chi <- raster::getData("GADM", country = "CHL", level = 0)
chi@data
#
e <- extent(-77,-72,-46,-41)
#e2 <- extent(-70,-35,-68,-60)
rc <- crop(chi, e)
proj4string(rc) <- CRS("+init=epsg:4326")
rc3 <- st_as_sf(rc) # par dejarlo en formato geom_sf

# Saco bathymetria
bat <- getNOAA.bathy(-77,-72,-46,-41, res = 10)
```

Preparo la grilla para los diversos indicadores.

```{r}
Grid2<- rc3 %>% #rc3 es el plot base original linea 487
  sf::st_make_grid(cellsize = c(0.125,0.125)) %>% # para que quede cuadrada
  sf::st_cast("MULTIPOLYGON") %>%
  sf::st_sf() %>% # objeto en spatial feature
  dplyr::mutate(cellid = row_number()) 

# la pruebo

ggplot() +
  geom_contour(data = bat,
               aes(x=x, y=y, z=z),
               breaks=c(0, -10, -20, -50, -100, -200, -1000),
               linewidth=0.2,
               colour="grey")+
  geom_sf(data = Grid2, 
          color="grey",  
          fill=NA, 
          size=0.3) +
  geom_sf(data = rc3,  fill=NA)+
  theme_minimal()

```

Cambio el formato y proyección de los datos crudos.

```{r eval=FALSE}

#transformar los datos en un sf object. Aqui ojo por q no cambié el nombre de las tallas =LONGITUD

dfta <- st_as_sf(tageo9623b %>% 
                  filter(ANO_ARR>2021),
                coords = c("LON", "LAT"),  
                  crs = 4326) 
# join data to grid; make sure to join points to grid
# the first object drives the output geometry
result2 <- Grid2 %>%
  st_join(dfta) %>% 
  group_by(cellid, ANO_ARR) %>% 
  summarize(MEANL = mean(LONGITUD, rm.na=TRUE)) %>% 
  filter(! is.na(MEANL))
```

```{r eval=FALSE}
ma <- ggplot() +
  geom_contour(data = bat,
               aes(x=x, y=y, z=z),
               breaks=c(0, -10, -20, -50, -100, -200, -1000),
               linewidth=0.2,
               colour="grey")+

  geom_sf(data=result2,  
          aes(fill = cut(MEANL,
                         breaks = seq(50, 120, by = 10))),
          color=NA) +
    geom_sf(data = rc3,  fill="white")+
  scale_fill_viridis_d(
                    labels =  seq(40, 100, by = 10), # if you must
                    option = "F",
                    name = "Tallas Medias (cm.)",
                    direction=-1) +
  facet_wrap(.~ANO_ARR)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, 
                                   hjust = 1,
                                   vjust=0,
                                   size = 6),
        axis.text.y = element_text(size = 6))+
  coord_sf(crs = 4326)+
  labs(x = "Longitude", y = "Latitude")+
  ylim(-45.8, -41.5)+
  xlim(-75, -72.5)
ma
```


# Recruit Index

Otra forma


```{r warning=FALSE}
cuantil_10pesq <- quantile(tageo9623b$LONGITUD, 0.10)
```


```{r warning=FALSE}
indice_reclutamiento <- tageo9623b %>%
  filter(LONGITUD<cuantil_10pesq) %>% 
  group_by(ANO_ARR, MES_ARR, POLIGONO, ZONA, POLIGONO_IFOP) %>%
  summarize(PROP = n() / nrow(tageo9623b)) %>% 
  mutate(PROPLOG =log(PROP))
# Crear gráficos en facet_wrap de barras para representar el índice de reclutamiento
```
Veo los datos crudos  con la linea como media del cuantil de los datos
```{r warning=FALSE}
indseg <- ggplot(indice_reclutamiento , 
       aes(x = factor(ANO_ARR), 
           y = PROP)) +
  geom_boxplot() +
  facet_wrap(POLIGONO~., ncol=4) +
  scale_x_discrete(breaks = seq(from = 1996, to = 2023, by = 4))+
  theme_few()+
    theme(axis.text.x = element_text(angle = 90, hjust = 1))+
   labs(x = "ANO", 
        y = "Índice de Reclutamiento")+
  ylim(0, 0.001)
indseg
```
Veo los datos normalizados con la linea como media del cuantil de los datos
```{r warning=FALSE}
indseg2 <- ggplot(indice_reclutamiento , 
       aes(x = factor(ANO_ARR), 
           y = PROPLOG)) +
  geom_boxplot() +
  facet_wrap(POLIGONO~., ncol=4) +
  geom_hline(yintercept = quantile(indice_reclutamiento$PROPLOG, 0.5), 
             color = "blue")+
  scale_x_discrete(breaks = seq(from = 1996, to = 2022, by = 4))+
  theme_few()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
   labs(x = "ANO", 
        y = "Índice de Reclutamiento")
indseg2
```


ahora estandarizo los datos entre -1 y 1.

```{r warning=FALSE}
a <- -1  # Límite inferior del rango objetivo
b <- 1   # Límite superior del rango objetivo

# Calcular el valor mínimo y máximo de tus datos
min_x <- min(indice_reclutamiento$PROPLOG)
max_x <- max(indice_reclutamiento$PROPLOG)

# Aplicar la fórmula de normalización
indice_reclutamiento$PROPLOG2 <- ((indice_reclutamiento$PROPLOG- min_x) / (max_x - min_x)) * (b - a) + a
```


Por poligono
```{r warning=FALSE, message=FALSE}
indseg3 <- ggplot(indice_reclutamiento  %>% 
  group_by(ANO_ARR,POLIGONO) %>%
  summarise(PROPLOG3=mean(PROPLOG2)), 
       aes(x = factor(ANO_ARR), 
           y = PROPLOG3,
           fill=PROPLOG3 > 0)) +
  geom_bar(stat = "identity")  +
  scale_fill_manual(values = c("black", "grey"),
                    labels = c("Negativo", "Positivo"),
                    name="IR Erizo") +
  facet_wrap(.~POLIGONO) +
  geom_hline(yintercept = 0, color = "red")+
  scale_x_discrete(breaks = seq(from = 1996, to = 2023, by = 1))+
  theme_few()+
  theme(axis.text.x = element_text(angle = 90, 
                                   hjust = 1,
                                   vjust=0,
                                   size = 5))+
  labs(x = "ANO", 
        y = "Índice de Reclutamiento")
indseg3
```
por Zona

```{r warning=FALSE, message=FALSE}
indseg4 <- ggplot(indice_reclutamiento  %>% 
  group_by(ANO_ARR,ZONA) %>%
  summarise(PROPLOG3=mean(PROPLOG2)), 
       aes(x = factor(ANO_ARR), 
           y = PROPLOG3,
           fill=PROPLOG3 > 0)) +
  geom_bar(stat = "identity")  +
  scale_fill_manual(values = c("black", "grey"),
                    labels = c("Negativo", "Positivo"),
                    name="IR Erizo") +
  facet_wrap(.~ZONA) +
  geom_hline(yintercept = 0, color = "red")+
  scale_x_discrete(breaks = seq(from = 1996, to = 2023, by = 1))+
  theme_few()+
  theme(axis.text.x = element_text(angle = 90, 
                                   hjust = 1,
                                   vjust=0,
                                   size = 5))+
  labs(x = "ANO", 
        y = "Índice de Reclutamiento")+
  ylim(-1,1)
indseg4
```
Escribir una tabla con los indices para cruzar con biomasas

```{r}
indice_corr <- round(indice_reclutamiento  %>% 
  group_by(ANO_ARR,ZONA) %>%
  summarise(PROPLOG3=mean(PROPLOG2)),3)

write_csv(indice_corr, "indice_corr.csv")
```
## Correlación

```{r}
Bio6023 <- read_csv("~/IFOP/Erizo_SA/2024/Erizo_65_23/Biomasas_60_23.csv")
Reclu <- read_csv("indice_corr.csv")
CPUE <- read_csv("datacpue_erizo_96_23.csv")
```


```{r}
Bio9623 <- Bio6023 %>% 
  filter(Años>1995,
         BIO !="Biomasa Total",
         Años!="2018") %>% 
  rename("ANO_ARR"=Años,
         "ZONA"=BIO) %>% 
  mutate(ZONA = case_when(
           ZONA == "Biomasa Total X Norte" ~ 1,
           ZONA == "Biomasa Total X Sur" ~ 2,
           ZONA == "Biomasa Total XI" ~ 3)) %>% 
  mutate(VALUELAG = lag(VALUE, 1))

Reclu2 <- Reclu %>% 
  rename("VALUERECLU"=PROPLOG3) 

datacorr <- full_join(Bio9623, Reclu2, 
                      by =c("ANO_ARR", "ZONA"))


# ordenar data CPUE
CPUE1 <- CPUE %>% 
  mutate(CPUELAG = lag(CPUE2, 1))
datacorrcpue<- full_join(CPUE1, Reclu2, 
                      by =c("ANO_ARR", "ZONA"))


```


```{r}
plotcorr <- ggplot(datacorr, 
                   aes(x = VALUERECLU,
           y = log(VALUELAG), 
           label = ANO_ARR)) +
  geom_point() +
  geom_smooth(method="lm",
              se=FALSE)+
  geom_text(nudge_x = 0.1, 
            nudge_y = 0.01,
            size=3) +  
  labs(title = "", 
       x = "", 
       y = "Log(BD)") +
  theme_few()+
  facet_wrap(.~ZONA,
             scales = "free_x")+
  xlim(-1,1)

```


```{r}
plotcorrcpue <- ggplot(datacorrcpue, 
                   aes(x = VALUERECLU,
           y = CPUELAG, 
           label = ANO_ARR)) +
  geom_point() +
  geom_smooth(method="lm",
              se=FALSE,
              col=2)+
  geom_text(nudge_x = 0.1, 
            nudge_y = 0.01,
            size=3) +  
  labs(title = "", 
       x = "Ind Reclutamiento", 
       y = "CPUE") +
  theme_few()+
  facet_wrap(.~ZONA,
             scales = "free_x")+
  xlim(-1,1)
```


```{r warning=FALSE, message=FALSE}
plotcorr/ plotcorrcpue
```

Hago un test de correlación entre reclutamiento y biomasa por zona
```{r}
# Inicializar un vector para almacenar los resultados
resultados_correlacion <- vector("list", 
                                 length = length(unique(datacorr$ZONA)))

# Realizar el test de Pearson por ZONA
for (zona_actual in unique(datacorr$ZONA)) {
  datos_zona <- subset(datacorr, ZONA == zona_actual)
  
  # Aplicar el test de Pearson
  resultado_correlacion <- cor.test(datos_zona$VALUELAG, 
                                    datos_zona$VALUERECLU,
                                    method="pearson")
    # Almacenar los resultados
  resultados_correlacion[[zona_actual]] <- resultado_correlacion
}

# Imprimir los resultados
for (zona_actual in unique(datos$ZONA)) {
  cat("Zona:", zona_actual, "\n")
  print(resultados_correlacion[[zona_actual]])
  cat("\n")
}

resultados_correlacion
```


Hago un test de correlación entre reclutamiento y CPUE por zona


```{r}
# Inicializar un vector para almacenar los resultados
resultados_correlacioncpue <- vector("list", 
                                     length = length(unique(datacorrcpue$ZONA)))

# Realizar el test de Pearson por ZONA
for (zona_actual in unique(datacorrcpue$ZONA)) {
  datos_zona <- subset(datacorrcpue, ZONA == zona_actual)
  
  # Aplicar el test de Pearson
  resultado_correlacioncpue <- cor.test(datos_zona$CPUELAG, 
                                    datos_zona$VALUERECLU,
                                    method="pearson")
    # Almacenar los resultados
  resultados_correlacioncpue[[zona_actual]] <- resultado_correlacioncpue
}

# Imprimir los resultados
for (zona_actual in unique(datacorrcpue$ZONA)) {
  cat("Zona:", zona_actual, "\n")
  print(resultados_correlacioncpue[[zona_actual]])
  cat("\n")
}

resultados_correlacioncpue
```




